{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The washing out of the priors\n",
    "\n",
    "People object to Bayesianism on the ground that the prior is subjective. \n",
    "\n",
    "One Bayesian response is that the differences between priors get \"washed out\" as one further and further updates.\n",
    "\n",
    "In traditional Bayesian texts, this response is conveyed by way of describing idealized likelihoods and idealized data and showing that if one updates repeatedly the differences between priors gets smaller and smaller.\n",
    "\n",
    "However, this can be illustrated in a more hands-on manner as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before proceeding further\n",
    "\n",
    "Before proceeding further, please follow the following instructions:\n",
    "\n",
    "1. Click on the <i class=\"fa fa-rocket\" aria-hidden=\"true\"></i> icon at the top center-right, which will launch the page in a binder (experience suggests that Firefox and Chrome work best)\n",
    "\n",
    "2. After it loads (it takes about 3-5 minutes), use the menu bars to access:\n",
    "\n",
    "- View | Collapse All Code\n",
    "\n",
    "- Run | Run All Cells\n",
    "\n",
    "3. Click on the three dots right below \"Setting four values\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting four values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500     # number of trials n in Binom(n,θ)\n",
    "\n",
    "m = 99     # number of elements m of the parameter space {1/(m+1), 2/(m+1), ..., m/(m+1)} \n",
    "\n",
    "            # θ_i refers to (i+1)/(m+1) for i=0,1,...,m-1\n",
    "\n",
    "            # e.g. θ_0 is 1/(m+1), θ_1 is 2/(m+1), θ_2 is 3/(m+1), ... , θ_{m-1} is m/(m+1)\n",
    "\n",
    "my_data = [185, 167, 189, 439, 89, 255, 222, 408, 190, 57]  \n",
    "\n",
    "        # as many data points as you want, as long as they are integers ≤ n\n",
    "\n",
    "my_non_uniform_value = 0.5\n",
    "\n",
    "        # change the prior probability so that (m/2)/(m+1)) has this value, and the others are uniform across the remaining amount\n",
    "\n",
    "        # e.g. if you choose .5 then the other m-1 many parameters will be set to .5/(m-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem \n",
    "\n",
    "Three separate times, \n",
    "\n",
    "- choose values of n,m,my_data, and my_non_uniform_value and write them down\n",
    "\n",
    "- choose the menu option Run | Run All Cells\n",
    "\n",
    "- look at the outcomes in the two seires of pie chairs and write down in 1-2 complete English sentences whether the last posterior in the uniform case ended up being similar to the last posterior in the non-uniform case\n",
    "\n",
    "- for full credit, get at least one example where the last posteriors were different and write 1-2 sentences offering an explanation of what was responsible for this non-washing-out-of-the-priors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome with uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, poisson, binom\n",
    "from tabulate import tabulate\n",
    "import matplotlib\n",
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt   # load pyplot package\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def bayes_pie(size_sample_space,size_parameter_space,prior,likelihood, observed_values):\n",
    "\n",
    "    n = len(observed_values)\n",
    "\n",
    "    parameter_space = list(range(size_parameter_space))\n",
    "\n",
    "    k, r = divmod(n, 3)\n",
    "\n",
    "    fig, axs = plt.subplots(k+1, 3, figsize=(10, 2*(k+1))) \n",
    "\n",
    "    labels = ['θ_'+str(i) for i in range(size_parameter_space)]  \n",
    "\n",
    "    sorted_prior_indices = np.argsort(prior)\n",
    "    above_02_indices = [i for i in sorted_prior_indices if prior[i] > 0.02]\n",
    "    labels_prior = [labels[i] if i in above_02_indices else '' for i in range(size_parameter_space)]\n",
    "\n",
    "    axs[0,0].pie(prior, labels = labels_prior)\n",
    "\n",
    "    axs[0,0].set_title('prior')  \n",
    "\n",
    "    for j in range(n):\n",
    "\n",
    "        evidence = sum([prior[i]*likelihood[i][observed_values[j]] for i in range(size_parameter_space)])\n",
    "\n",
    "        posterior = [prior[i]*likelihood[i][observed_values[j]]/evidence for i in range(size_parameter_space)]\n",
    "\n",
    "        sorted_posterior_indices = np.argsort(posterior)\n",
    "        above_02_indices = [i for i in sorted_posterior_indices if posterior[i] > 0.02]\n",
    "        labels_posterior = [labels[i] if i in above_02_indices else '' for i in range(size_parameter_space)]\n",
    "\n",
    "        prior = posterior\n",
    "\n",
    "        if j < 2:\n",
    "            axs[0,j+1].pie(posterior, labels=labels_posterior)\n",
    "            axs[0,j+1].set_title('posterior_'+str(j+1))\n",
    "        else:\n",
    "            i1, j1 = divmod(j+1, 3)\n",
    "            axs[i1,j1].pie(posterior, labels=labels_posterior)\n",
    "            axs[i1,j1].set_title('posterior_'+str(j+1))\n",
    "\n",
    "    for j in range(n, 3*k+2):\n",
    "        i1, j1 = divmod(j+1, 3)\n",
    "        axs[i1,j1].axis('off')\n",
    "\n",
    "    return posterior\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def bayes_pie_binomial(n,m, prior, observed_values):\n",
    "\n",
    "    my_likelihood = [[None]*n for _ in range(m)]\n",
    "\n",
    "    my_sample_space = np.arange(0, n)\n",
    "\n",
    "    my_likelihood = [[None]*m for _ in range(m)]\n",
    "\n",
    "    for i in range(m):\n",
    "\n",
    "        my_likelihood[i] = binom.pmf(my_sample_space, n, (i+1)/(m+1))\n",
    "\n",
    "    bayes_pie(n,m, prior, my_likelihood, observed_values)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "my_uniform_prior = [1/m]*m\n",
    "\n",
    "bayes_pie_binomial(n, m, my_uniform_prior, my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome with non-uniform prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "my_nonuniform_prior = [0 for _ in range(m)]\n",
    "\n",
    "my_nonuniform_prior = [(1-value_for_non_uniform_prior)/m] * m\n",
    "\n",
    "my_nonuniform_prior[m//2] = value_for_non_uniform_prior \n",
    "\n",
    "bayes_pie_binomial(n, m, my_nonuniform_prior, my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
